{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the MagnaTagATune Dataset for Music Genre Classification\n",
    "\n",
    "Arun Das\n",
    "\n",
    "Research Fellow,\n",
    "\n",
    "Open Cloud Institute,\n",
    "\n",
    "The University of Texas at San Antonio.\n",
    "\n",
    "arun.das@my.utsa.edu\n",
    "\n",
    "A little bit about me: I am a Computer Engineer by trade with research concentration on cloud computing and deep learning. I started researching on deep learning only a year (and half) back with emphasis on computer vision. So, I'm still on the learning curve when it comes to advanced DL topics in some other areas. This notebook is the first step in the deep learning pipeline of an interesting Music Genre Classification problem: the intense data science part where you prepare the dataset in the way you want.\n",
    "\n",
    "The dataset used for the project is MagnaTagATune. It has more than 25K mp3 files. The aim of the project is in using a deep neural network to predict the genre of music, provided the mp3 as an input. The way it is achieved is through a combination of convolutional and reccurent neural networks working together as a whole.\n",
    "\n",
    "I used pandas to work with the dataset which contains annotations of each of the 25K mp3 files. These annotations contains information about the genre, file id, mp3 file location etc. Pandas is an easy, flexible and powerful tool with many functions related to data structures for data analysis, time series analysis and statistics. After the dataset is processed, the mp3 file as such needs to be converted from raw mp3 to Mel-scaled power spectrogram. We use librosa to do it. You can see an example here.\n",
    "\n",
    "Let's do it then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd0834a3fedd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#Set number of columns to show in the notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "#Imported required librariries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import librosa\n",
    "#Set number of columns to show in the notebook\n",
    "pd.set_option('display.max_columns',200)\n",
    "#Set number of rows to show in the notebook\n",
    "pd.set_option('display.max_rows',50)\n",
    "#Make the graphs a bit prettier\n",
    "pd.set_option('display.mpl_style','default')\n",
    "\n",
    "#Import Matplotlib Package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Display pictures within the notebook itself\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'annotations_final.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a21c3db555ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#read the annotations file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnewdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'annotations_final.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Ankit Gupta\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ankit Gupta\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ankit Gupta\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ankit Gupta\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ankit Gupta\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'annotations_final.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#read the annotations file\n",
    "newdata = pd.read_csv('annotations_final.csv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Display the top 5 rows\n",
    "    newdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get to know the data better\n",
    "newdata.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what columns are there?\n",
    "newdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract the clip_id and mp3_path\n",
    "newdata[[\"clip_id\",\"mp3_path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Previous command extracted it as a Daaframe. We need it as a matrix to do analytics on.\n",
    "#Extract clip_id and mp3_path as a matrix.\n",
    "clip_id, mp3_path = newdata[[\"clip_id\",\"mp3_path\"]].as_matrix([:,0],newdata[[\"clip_id\",\"mp3_path\"]].as_matrix()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some of the tags in the dataset are really close to each other.Lets merge them together\n",
    "synonyms = [['beat', 'beats'],\n",
    "            ['chant', 'chanting'],\n",
    "            ['choir', 'choral'],\n",
    "            ['classical', 'clasical', 'classic'],\n",
    "            ['drum', 'drums'],\n",
    "            ['electro', 'electronic', 'electronica', 'electric'],\n",
    "            ['fast', 'fast beat', 'quick'],\n",
    "            ['female', 'female singer', 'female singing', 'female vocals', 'female vocal', 'female voice', 'woman', 'woman singing', 'women'],\n",
    "            ['flute', 'flutes'],\n",
    "            ['guitar', 'guitars'],\n",
    "            ['hard', 'hard rock'],\n",
    "            ['harpsichord', 'harpsicord'],\n",
    "            ['heavy', 'heavy metal', 'metal'],\n",
    "            ['horn', 'horns'],\n",
    "            ['india', 'indian'],\n",
    "            ['jazz', 'jazzy'],\n",
    "            ['male', 'male singer', 'male vocal', 'male vocals', 'male voice', 'man', 'man singing', 'men'],\n",
    "            ['no beat', 'no drums'],\n",
    "            ['no singer', 'no singing', 'no vocal','no vocals', 'no voice', 'no voices', 'instrumental'],\n",
    "            ['opera', 'operatic'],\n",
    "            ['orchestra', 'orchestral'],\n",
    "            ['quiet', 'silence'],\n",
    "            ['singer', 'singing'],\n",
    "            ['space', 'spacey'],\n",
    "            ['string', 'strings'],\n",
    "            ['synth', 'synthesizer'],\n",
    "            ['violin', 'violins'],\n",
    "            ['vocal', 'vocals', 'voice', 'voices'],\n",
    "            ['strange', 'weird']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge the Synonyms and drop all other columns than the first one.\n",
    "\"\"\"\n",
    "Example:\n",
    "Merge 'beat','beats' and save it to 'beat'.\n",
    "Merge 'classical','clasical','classic'and save it to 'classical'.\n",
    "\"\"\"\n",
    "for synonym_list in synonyms:\n",
    "    newdata[synonm_list[0]] = newdata[synonym_list].max(axis=1)\n",
    "    newdata.drop(synonym_list[1:],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Did it Work?\n",
    "newdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets view it.\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the mp3_math tag from the dataframe\n",
    "newdata.drop('mp3_path',axis=1,inplace=True)\n",
    "#Save the column names into a variable\n",
    "data =newdata.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find THe distribution of tags\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort the column names.\n",
    "data.sort_values(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the top tags from the dataframe\n",
    "topindex, topvalues = list(data.index[84:]),data.values[84:]\n",
    "del(topindex[-1])\n",
    "topvalues = np.delete(topvalues, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the top column names\n",
    "topindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the top column values\n",
    "topvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get a list of columns to remove\n",
    "rem_cols=data.index[:84]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross-check: How many columns are we removing?\n",
    "len(rem_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the columns that need to be removed\n",
    "newdata.drop(rem_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a backup of the dataframe\n",
    "backup_newdata = newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this to revive the dataframe\n",
    "newdata = backup_newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle the dataframe\n",
    "from sklearn.utils import shuffle\n",
    "newdata = shuffle(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This method may be used to shuffle data.\n",
    "#By setting frac=1, you''ll shuffle every single row randomly.\\\n",
    "newdata = newdat.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Final check\n",
    "newdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us save the final columns\n",
    "final_columns_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do it only once to  delete the clip_id column\n",
    "del(final_columns_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verified\n",
    "final_columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the  file which is to be saved off(you could skip and apply similiar steps in the previous dataframe )\n",
    "#Here, binary 0's and 1's from each column is changed to 'False' and 'True' by using'==' operator on the dataframe.\n",
    "final_matrix=pd.concat([newdata['clip_id'],newdata[final_columns_names]==1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps will convert mp3 files into their respective mel-spectrogram. This is compute intensive. If it takes a long time, copy it over to a text tile and run it as a python script so that you can forget about the jupyter notebook session. I've run these once, so not running them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename all the mp3 files to their clip_id and save it into one folder named 'dataset_clip_id_mp3' in the same folder.\n",
    "#Get the current working directory\n",
    "root = os.getcwd()\n",
    "os.mkdir(root+\"/dataset_clip_id_mp3/\",0755)\n",
    "\n",
    "#Iterate over the mp3 files, rename them to clip_id and save it to another folder.\n",
    "for id in range(25863):\n",
    "    \n",
    "#print clip_id[id], mp3_path[id]\n",
    "src =root + \"/\" + mp3_path[id]\n",
    "dest = root + \"/dataset_clip_id_mp3\" + str(clip_id[id])+\".mp3\"\n",
    "shur=til.copy2(src,dest)\n",
    "#Print src,dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert all the mp3 files into their corresponding mel-spectroprograms(melgrams).\n",
    "\n",
    "#Audio preprocessing function\n",
    "def compute_melgram(audio_path):\n",
    "    ''' Compute a mel-spectrogram and returns it in a shape of (1,1,96,1366), where\n",
    "    96 == #mel-bins and 1366 == #time frame\n",
    "    parameters\n",
    "    ----------\n",
    "    audio_path: path for the audio file.\n",
    "                Any format supported by audioread will work.\n",
    "    More info: http://librosa.github.io/librosa/generated/librosa.core.load.html#librosa.core.load\n",
    "    '''\n",
    "    \n",
    "    #Mel-spectrogram parameters\n",
    "    SR =12000\n",
    "    N_FFT = 512\n",
    "    N_MELS = 96\n",
    "    HOP_LEN = 256\n",
    "    DURA = 29.12 #To make it 1366 fram..\n",
    "    \n",
    "    src, sr = librosa.load(audio_path, sr=SR) #Whole signal\n",
    "    n_samples = src.shape[0]\n",
    "    n_sample_fit = int(Dura*SR)\n",
    "    \n",
    "    if n_sample < n_sample_fit: #if too short\n",
    "        src = np.hstack((src, np.zeros((int(DURA*SR)-n_sample,))))\n",
    "    elif n_sample > n_sample fit: #if too long\n",
    "        src= src[(n_sample-n_sample_fit)/2:(n_sample+n_sample_fit)/2]\n",
    "    logam = librosa.logamplitude\n",
    "    melgram = librosa.feature.melspectrogram\n",
    "    ret = logam(melgram(y=src, sr=SR, hop_length =HOP_LEN,\n",
    "                       n_fft=N_FFT, n_mels =N_MELS))**2,ref_power=1.0)\n",
    "    ret=ret[np.newaxis, np.newaxis,:]\n",
    "    return ret\n",
    "\n",
    "#GET the absolute path of all audio files and save it to audio_paths arrays[]\n",
    "audio_paths=[]\n",
    "#Variable to save the mp3 files that don't work\n",
    "files_that_dont_work=[]\n",
    "os.chidr('/home/cc/notebooks/MusicProject/MagnaagATune/')\n",
    "root= os.getcwd()\n",
    "os.chidr(root + 'daaset_clip_id_mp3/')\n",
    "for audio_pah in os.listdir('.'):\n",
    "    #Audio_paths.append(os.path.abspath(fname))\n",
    "    if os.path.isfile(root + '/dataset_clip_id_melgram/' + str(os.path.splitext(audio_path)[0])+'.npy'):\n",
    "        #Print \"existtt\"\n",
    "        continue\n",
    "    else:\n",
    "        if str(os.path.splitext(audio_path)[1]) == \".mp3\":\n",
    "            try:\n",
    "                melgram = compute_melgram(os.path.abspath(audio_path))\n",
    "                dest = root + '/dataset_clip_id_melgram' + str(os,path.splitext(audio_path)[0])\n",
    "                np.save(dest, melgram)\n",
    "            except EOFError:\n",
    "                files_that_dont_work.append(audio_path)\n",
    "                continue\n",
    "    \n",
    "                \n",
    "\"\"\"\n",
    "NOTE: I've run this an created all the mel-spectrograms and saved them off seprately, \n",
    "and then concatenated the train, test and validation set in the ratio that I wanted.\n",
    "This, will make a significant overhead in the computation time when you look at this\n",
    "as a whole. \n",
    "\n",
    "For example, concatenating the corresponding files to train, test and\n",
    "validation splits will inturn require more time and memory. If we decide the splits \n",
    "beforehand and converting mp3 to mel-spectrogram based on those splits, it will make\n",
    "life much easier (and less time). \n",
    "\n",
    "However, I want each of the mel-spectrograms seperate as I might need to create datasets\n",
    "based on different genre, number of files, splits etc. in the future. So this is the way\n",
    "to go for me now. Please note that this requires a significant amount of system memory.\n",
    "\"\"\"                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get  a list of\n",
    "mp3_available = []\n",
    "melgram_available=[]\n",
    "for mp3 in os.listdir('/home/cc/notebooks/MusicProject/MagnaTagATune/dataset_clip_id_mp3/'):\n",
    "     mp3_available.append(int(os.path.splitext(mp3)[0]))\n",
    "        \n",
    "for melgram in os.listdir('/home/cc/notebooks/MusicProject/MagnaTagATune/dataset_clip_id_melgram/'):\n",
    "     melgram_available.append(int(os.path.splitext(melgram)[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The latest clip_id\n",
    "new_clip_id = final_matrix['clip_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us see which all files have not been converted into melspectrograms.\n",
    "set(list(new_clip_id)).difference(melgram_avilable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saw that these clips were extra 35644, 55753, 57881. Removing them.\n",
    "final_matrix = final_matrix[final_matrix['clip_id']!= 35644]\n",
    "final_matrix = final_matrix[final_matrix['clip_id']!= 55753]\n",
    "final_matrix = final_matrix[final_matrix['clip_id']!= 57881]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check again\n",
    "final_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the matrix\n",
    "final_matrix.to_pickle('final_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is how you can load it afterwards.\n",
    "final_matrix = pd.read_pickle('final_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate the Training , tes and validation dataframe.\n",
    "training_with_clip =final_matrix[:19773]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_with_clip = final_matrix[19773:21294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_with_clip=final_matrix[21294:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quick peek\n",
    "training_with_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quick peek\n",
    "testing_with_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quick peek\n",
    "validation_with_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract the corresponding clip_id's\n",
    "training_clip_id = training_with_clip['clip_id'].values\n",
    "validation_clip_id = validation_wit_clip['clip_id'].values\n",
    "testing_clip_id = testing_wit_clip['clip_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check !\n",
    "training_clip_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Go to the directory you want to save the dataframe\n",
    "os.chdir('/home/cc/notebooks/MusicProject/MagnaTagATune/final_dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the 'y' values.\n",
    "np.save('train_y.npy', training_with_clip[final_columns_names].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('valid_y.npy',validation_with_clip[final_columns_names].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('test_y.npy', testing_with_clip[final_columns_names].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the 'x' clip_id's. We will make the numpy array using this.\n",
    "np.savetxt('train_x_clip_id.txt', training_with_clip['clip_id'].values, fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('test_x_clip_id.txt', testing_with_clip['clip_id'].values, fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('valid_x_clip_id.txt', validation_with_clip['clip_id'].values, fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it, the (most) compute intensive part - concatenating the numpy arrays to form train, test and validation splits. In the training file portion, I have included two different ways in which you can create the train split; either by concatenating the numpy arrays or directly converting from corresponding mp3's to melspectrogram.\n",
    "\n",
    "melgram = compute_melgram(str(train_clip) + '.mp3')\n",
    "\n",
    "OR\n",
    "\n",
    "melgram = np.load(str(train_clip) + '.npy')\n",
    "\n",
    "Use the one which suits you. I had a cloud instance with plenty RAM, so I concatenated the numpy arrays. It took about 6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now to combine the melgrams according to the clip_id.\n",
    "#(maybe in the future we can make melgrams accordiing to th clip id itself into train and validation!!)\n",
    "\n",
    "#Variable to store melgrams.\n",
    "train_x = np.zeros((0, 1, 96, 1366))\n",
    "test_x = np.zeros((0, 1, 96, 1366))\n",
    "valid_x = np.zeros((0, 1, 96, 1366))\n",
    "\n",
    "root = '/home/cc/notebooks/MusicProject/MagnaTagATune/'\n",
    "os.chdir(root + \"/dataset_clip_id_melgram/\")\n",
    "for i,valid_clip in enumerate(list(validation_clip_id)):\n",
    "    if os.path.isfile(str(valid_clip) + '.npy'):\n",
    "        #print i,valid_clip\n",
    "        melgram = np.load(str(valid_clip) + '.npy')\n",
    "        valid_x = np.concatenate((valid_x, melgram), axis=0)\n",
    "os.chdir('/home/cc/notebooks/MusicProject/MagnaTagATune/')\n",
    "np.save('valid_x.npy', valid_x)\n",
    "print \"Validation file created\"\n",
    "\n",
    "\n",
    "root = '/home/cc/notebooks/MusicProject/MagnaTagATune/'\n",
    "os.chdir(root + \"/dataset_clip_id_melgram/\")\n",
    "for i,test_clip in enumerate(list(testing_clip_id)):\n",
    "    if os.path.isfile(str(test_clip) + '.npy'):\n",
    "        #print i,test_clip\n",
    "        melgram = np.load(str(test_clip) + '.npy')\n",
    "        test_x = np.concatenate((test_x, melgram), axis=0)\n",
    "os.chdir('/home/cc/notebooks/MusicProject/MagnaTagATune/')\n",
    "np.save('test_x.npy', test_x)\n",
    "print \"Testing file created\"\n",
    "\n",
    "root = '/home/cc/notebooks/MusicProject/MagnaTagATune/'\n",
    "os.chdir(root + \"/dataset_clip_id_melgram/\")\n",
    "for i,train_clip in enumerate(list(training_clip_id)):\n",
    "    #if os.path.isfile(str(train_clip) + '.npy'):\n",
    "        #print i,train_clip\n",
    "    melgram = compute_melgram(str(train_clip) + '.mp3')\n",
    "    #melgram = np.load(str(train_clip) + '.npy')\n",
    "    train_x = np.concatenate((train_x, melgram), axis=0)\n",
    "os.chdir('/home/cc/notebooks/MusicProject/MagnaTagATune/')\n",
    "np.save('train_x.npy', train_x)\n",
    "print \"Training file created.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "That's it for now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
